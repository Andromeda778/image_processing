{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль 2. Классификация изображений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сопоставление изображений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы сопоставления изображений\n",
    "\n",
    "Для реализации алгоритма классификации изображений, я предложу вам пример кода, использующий библиотеку tensorflow и keras. В этом примере мы будем использовать предварительно обученную модель MobileNetV2 для классификации изображений.\n",
    "\n",
    "Прежде всего, убедитесь, что у вас установлены tensorflow и keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import (\n",
    "    preprocess_input,\n",
    "    decode_predictions,\n",
    ")\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Загрузка предварительно обученной модели MobileNetV2\n",
    "model = MobileNetV2(weights=\"imagenet\")\n",
    "\n",
    "\n",
    "def classify_image(img_path):\n",
    "    # Загрузка изображения, его предварительная обработка и расширение размерностей\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_image = preprocess_input(img_array_expanded_dims)\n",
    "\n",
    "    # Прогнозирование и декодирование предсказаний\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    results = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "    # Вывод результатов\n",
    "    for i, (imagenet_id, label, score) in enumerate(results):\n",
    "        print(f\"{i + 1}: {label} ({score*100:.2f}%)\")\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "img_path = \"./data/texture_01.jpg\"\n",
    "classify_image(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение мозаики из изображений\n",
    "\n",
    "Для построения мозаики изображений на Python, можно использовать библиотеку PIL (Python Imaging Library), которая теперь доступна как Pillow. Ниже приведен пример кода, который создает мозаику из нескольких изображений. Допустим, у нас есть четыре изображения, и мы хотим их объединить в одно большое изображение-мозаику в формате 2x2.\n",
    "\n",
    "Прежде всего, убедитесь, что у вас установлена библиотека Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def crop_to_square(img, size):\n",
    "    \"\"\"\n",
    "    Обрезка изображения до квадратной формы по центру.\n",
    "    \"\"\"\n",
    "    # Определение текущих размеров\n",
    "    width, height = img.size\n",
    "\n",
    "    # Определение размера для обрезки\n",
    "    new_size = min(width, height, size)\n",
    "\n",
    "    # Вычисление координат для обрезки\n",
    "    left = (width - new_size) / 2\n",
    "    top = (height - new_size) / 2\n",
    "    right = (width + new_size) / 2\n",
    "    bottom = (height + new_size) / 2\n",
    "\n",
    "    # Обрезка и возврат изображения\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    return img.resize((size, size), Image.Resampling.LANCZOS)\n",
    "\n",
    "\n",
    "# Пути к изображениям, которые будут включены в мозаику\n",
    "image_paths = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\", \"image4.jpg\"]\n",
    "\n",
    "# Открытие изображений и их сохранение в список\n",
    "images = [Image.open(f\"./data/{x}\") for x in image_paths]\n",
    "\n",
    "# Определение минимального размера среди всех изображений\n",
    "min_size = min(min(img.size) for img in images)\n",
    "\n",
    "# Обрезка изображений до квадратов и изменение их размера\n",
    "squared_images = [crop_to_square(img, min_size) for img in images]\n",
    "\n",
    "# Создание нового пустого изображения для мозаики\n",
    "mosaic_size = (min_size * 2, min_size * 2)\n",
    "mosaic_image = Image.new(\"RGB\", mosaic_size, (255, 255, 255))\n",
    "\n",
    "# Размещение изображений в мозаике\n",
    "positions = [(0, 0), (min_size, 0), (0, min_size), (min_size, min_size)]\n",
    "for img, pos in zip(squared_images, positions):\n",
    "    mosaic_image.paste(img, pos)\n",
    "\n",
    "# Сохранение и показ мозаики\n",
    "mosaic_image.save(\"./result/mosaic.jpg\")\n",
    "mosaic_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение панорамных изображений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_panorama(image1_path, image2_path, output_path=\"panorama.jpg\"):\n",
    "    # Загружаем изображения\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    image2 = cv2.imread(image2_path)\n",
    "\n",
    "    # Инициализируем ORB детектор\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Находим ключевые точки и дескрипторы с помощью ORB\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(image1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(image2, None)\n",
    "\n",
    "    # Создаем объект BFMatcher и совершаем сопоставление дескрипторов\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    # Сортируем сопоставления по расстоянию (лучшие сопоставления первые)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Извлекаем координаты соответствующих ключевых точек для сопоставленных дескрипторов\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "        points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "    # Находим матрицу гомографии\n",
    "    H, _ = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Применяем преобразование гомографии к изображению 1\n",
    "    height, width, channels = image2.shape\n",
    "    panorama = cv2.warpPerspective(image1, H, (width * 2, height))\n",
    "\n",
    "    # Копируем изображение 2 в панорамное изображение\n",
    "    panorama[0 : image2.shape[0], 0 : image2.shape[1]] = image2\n",
    "\n",
    "    # Сохраняем панорамное изображение\n",
    "    cv2.imwrite(output_path, panorama)\n",
    "\n",
    "\n",
    "# Пример использования:\n",
    "create_panorama(\"./data/panorama02.jpg\", \"./data/panorama01.jpg\", \"output_panorama.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
