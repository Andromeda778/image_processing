{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль 2. Классификация изображений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сопоставление изображений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы сопоставления изображений\n",
    "\n",
    "Для реализации алгоритма классификации изображений, я предложу вам пример кода, использующий библиотеку tensorflow и keras. В этом примере мы будем использовать предварительно обученную модель MobileNetV2 для классификации изображений.\n",
    "\n",
    "Прежде всего, убедитесь, что у вас установлены tensorflow и keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Загрузка предварительно обученной модели MobileNetV2\n",
    "model = MobileNetV2(weights=\"imagenet\")\n",
    "\n",
    "\n",
    "def classify_image(img_path):\n",
    "    # Загрузка изображения, его предварительная обработка и расширение размерностей\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_image = preprocess_input(img_array_expanded_dims)\n",
    "\n",
    "    # Прогнозирование и декодирование предсказаний\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    results = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "    # Вывод результатов\n",
    "    for i, (imagenet_id, label, score) in enumerate(results):\n",
    "        print(f\"{i + 1}: {label} ({score*100:.2f}%)\")\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "img_path = \"./data/texture_01.jpg\"\n",
    "classify_image(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение мозаики из изображений\n",
    "\n",
    "Для построения мозаики изображений на Python, можно использовать библиотеку PIL (Python Imaging Library), которая теперь доступна как Pillow. Ниже приведен пример кода, который создает мозаику из нескольких изображений. Допустим, у нас есть четыре изображения, и мы хотим их объединить в одно большое изображение-мозаику в формате 2x2.\n",
    "\n",
    "Прежде всего, убедитесь, что у вас установлена библиотека Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "def crop_to_square(img, size):\n",
    "    \"\"\"\n",
    "    Обрезка изображения до квадратной формы по центру.\n",
    "    \"\"\"\n",
    "    # Определение текущих размеров\n",
    "    width, height = img.size\n",
    "\n",
    "    # Определение размера для обрезки\n",
    "    new_size = min(width, height, size)\n",
    "\n",
    "    # Вычисление координат для обрезки\n",
    "    left = (width - new_size) / 2\n",
    "    top = (height - new_size) / 2\n",
    "    right = (width + new_size) / 2\n",
    "    bottom = (height + new_size) / 2\n",
    "\n",
    "    # Обрезка и возврат изображения\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    return img.resize((size, size), Image.Resampling.LANCZOS)\n",
    "\n",
    "\n",
    "# Пути к изображениям, которые будут включены в мозаику\n",
    "image_paths = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\", \"image4.jpg\"]\n",
    "\n",
    "# Открытие изображений и их сохранение в список\n",
    "images = [Image.open(f\"./data/{x}\") for x in image_paths]\n",
    "\n",
    "# Определение минимального размера среди всех изображений\n",
    "min_size = min(min(img.size) for img in images)\n",
    "\n",
    "# Обрезка изображений до квадратов и изменение их размера\n",
    "squared_images = [crop_to_square(img, min_size) for img in images]\n",
    "\n",
    "# Создание нового пустого изображения для мозаики\n",
    "mosaic_size = (min_size * 2, min_size * 2)\n",
    "mosaic_image = Image.new(\"RGB\", mosaic_size, (255, 255, 255))\n",
    "\n",
    "# Размещение изображений в мозаике\n",
    "positions = [(0, 0), (min_size, 0), (0, min_size), (min_size, min_size)]\n",
    "for img, pos in zip(squared_images, positions):\n",
    "    mosaic_image.paste(img, pos)\n",
    "\n",
    "# Сохранение и показ мозаики\n",
    "mosaic_image.save(\"./result/mosaic.jpg\")\n",
    "mosaic_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распознавание лиц\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "face = [\"3faces.jpg\", \"manyfaces.jpg\"]\n",
    "# Загрузка изображения\n",
    "image_path = f\"./data/faces/{face[0]}\"\n",
    "image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "# Нахождение лиц на изображении\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"Найдено лиц: {len(face_locations)}\")\n",
    "plt.imshow(image)\n",
    "for face_location in face_locations:\n",
    "    top, right, bottom, left = face_location\n",
    "    plt.plot([left, right, right, left, left], [top, top, bottom, bottom, top], \"r-\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "def resize_image(input_image_path, output_image_path, target_size):\n",
    "    with Image.open(input_image_path) as image:\n",
    "        original_width, original_height = image.size\n",
    "        max_dimension = max(original_width, original_height)\n",
    "        scale = target_size / max_dimension\n",
    "        new_width = int(original_width * scale)\n",
    "        new_height = int(original_height * scale)\n",
    "\n",
    "        resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        resized_image.save(output_image_path)\n",
    "\n",
    "\n",
    "def process_images_folder(input_folder, output_folder, target_size):\n",
    "    # Получение абсолютных путей папок\n",
    "    script_dir = os.getcwd()\n",
    "    abs_input_folder = os.path.join(script_dir, input_folder)\n",
    "    abs_output_folder = os.path.join(script_dir, output_folder)\n",
    "\n",
    "    if not os.path.exists(abs_output_folder):\n",
    "        os.makedirs(abs_output_folder)\n",
    "\n",
    "    for filename in os.listdir(abs_input_folder):\n",
    "        input_image_path = os.path.join(abs_input_folder, filename)\n",
    "        if os.path.isfile(input_image_path):\n",
    "            output_image_path = os.path.join(abs_output_folder, filename)\n",
    "            try:\n",
    "                resize_image(input_image_path, output_image_path, target_size)\n",
    "                print(f\"Image {filename} resized and saved to {output_folder}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "\n",
    "# Пути к папкам относительно скрипта\n",
    "input_folder = \"./data/plibrary/src\"\n",
    "output_folder = \"./data/plibrary/resampled\"\n",
    "target_size = 800  # Целевой размер для большей стороны изображения\n",
    "\n",
    "# Обработка всех изображений в папке\n",
    "process_images_folder(input_folder, output_folder, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "from shutil import copy2\n",
    "\n",
    "\n",
    "def filter_images_with_faces(source_folder, destination_folder):\n",
    "    # Создание папки назначения, если она не существует\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Перебор всех файлов в исходной папке\n",
    "    for filename in os.listdir(source_folder):\n",
    "        file_path = os.path.join(source_folder, filename)\n",
    "\n",
    "        # Убедитесь, что это файл и он имеет расширение изображения\n",
    "        if os.path.isfile(file_path) and filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            try:\n",
    "                # Загрузка изображения и поиск лиц\n",
    "                image = face_recognition.load_image_file(file_path)\n",
    "                face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "                # Если лица обнаружены, копировать файл в папку назначения\n",
    "                if len(face_locations) > 0:\n",
    "                    destination_path = os.path.join(destination_folder, filename)\n",
    "                    copy2(file_path, destination_path)\n",
    "                    print(f\"Image {filename} has faces and was copied.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "\n",
    "# Задайте пути к папкам\n",
    "script_dir = os.getcwd()\n",
    "source_folder = os.path.join(script_dir, \"./data/plibrary/resampled\")\n",
    "destination_folder = os.path.join(script_dir, \"./data/plibrary/justfaces\")\n",
    "\n",
    "# Фильтрация изображений\n",
    "filter_images_with_faces(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def create_directory_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def find_face_encodings(image_path):\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    return face_recognition.face_encodings(image)\n",
    "\n",
    "\n",
    "def are_faces_same(face_encoding, known_faces):\n",
    "    # Если нет известных лиц, не сравниваем\n",
    "    if len(known_faces) == 0:\n",
    "        return -1\n",
    "    distances = face_recognition.face_distance(known_faces, face_encoding)\n",
    "    best_match_index = distances.argmin()\n",
    "    if distances[best_match_index] < 0.6:\n",
    "        return best_match_index\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "source_folder = os.path.join(script_dir, \"./data/plibrary/justfaces\")\n",
    "destination_folder = os.path.join(script_dir, \"./data/plibrary/grouped\")\n",
    "create_directory_if_not_exists(destination_folder)\n",
    "\n",
    "known_faces = []\n",
    "face_folders = []\n",
    "\n",
    "# Перебор всех файлов в исходной папке\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        image_path = os.path.join(source_folder, filename)\n",
    "        image_encodings = find_face_encodings(image_path)\n",
    "\n",
    "        for encoding in image_encodings:\n",
    "            match_index = are_faces_same(encoding, known_faces)\n",
    "\n",
    "            if match_index != -1:\n",
    "                # Лицо совпадает с известным, копируем в соответствующую папку\n",
    "                shutil.copy2(image_path, face_folders[match_index])\n",
    "            else:\n",
    "                # Новое лицо, создаем для него папку\n",
    "                new_folder_path = os.path.join(destination_folder, f\"person_{len(known_faces)}\")\n",
    "                create_directory_if_not_exists(new_folder_path)\n",
    "                shutil.copy2(image_path, new_folder_path)\n",
    "\n",
    "                # Добавляем лицо и папку в известные\n",
    "                known_faces.append(encoding)\n",
    "                face_folders.append(new_folder_path)\n",
    "\n",
    "print(f\"Фотографии были сгруппированы по {len(known_faces)} лицам.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Коллекции для обучения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка набора данных LFW\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# Получение ссылок на изображения и их метки\n",
    "images = lfw_people.images\n",
    "target_names = lfw_people.target_names\n",
    "targets = lfw_people.target\n",
    "\n",
    "# Отображение первых 3 изображений\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "for i in range(3):\n",
    "    ax[i].imshow(images[i], cmap=\"gray\")\n",
    "    ax[i].set_title(target_names[targets[i]])\n",
    "    ax[i].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Квантование многомерных признаков\n",
    "\n",
    "КМП - это процесс преобразования непрерывных или многомерных признаков в дискретные значения, часто используемый для уменьшения количества различных признаков и упрощения алгоритмов машинного обучения, в том числе в контексте классификации изображений и поиска похожих изображений.\n",
    "\n",
    "В контексте классификации изображений и поиска похожих изображений, одним из распространенных подходов является использование векторов признаков, извлеченных из изображений с помощью предварительно обученных моделей глубокого обучения (например, сетей на основе архитектуры CNN). Квантование этих векторов признаков позволяет сократить объем хранимых данных и ускорить процесс сравнения изображений.\n",
    "\n",
    "В качестве примера, давайте рассмотрим использование предварительно обученной модели CNN для извлечения признаков из изображений и их последующее квантование с помощью алгоритма K-средних (K-means). Затем мы можем использовать эти квантованные признаки для поиска похожих изображений.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Загрузка предварительно обученной модели ResNet50 без верхнего слоя\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "\n",
    "def extract_features(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    return features.flatten()\n",
    "\n",
    "\n",
    "def get_features_from_folder(folder_path):\n",
    "    features_list = []\n",
    "    images_paths = []\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        if img_name.lower().endswith((\"png\", \"jpg\", \"jpeg\")):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            features = extract_features(img_path)\n",
    "            features_list.append(features)\n",
    "            images_paths.append(img_path)\n",
    "    return features_list, images_paths\n",
    "\n",
    "\n",
    "# Извлекаем признаки из всех изображений в папке\n",
    "folder_path = os.path.join(script_dir, \"./data/plibrary/justfaces\")\n",
    "features_list, images_paths = get_features_from_folder(folder_path)\n",
    "\n",
    "# Применяем K-средние для квантования признаков\n",
    "num_clusters = 3  # Примерное количество ожидаемых групп\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(features_list)\n",
    "\n",
    "# Находим индекс центроида для каждого изображения\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Группировка изображений по кластерам\n",
    "clustered_images = {}\n",
    "for i, label in enumerate(labels):\n",
    "    clustered_images.setdefault(label, []).append(images_paths[i])\n",
    "\n",
    "# Вывод результатов группировки\n",
    "\"\"\" for cluster_id, images in clustered_images.items():\n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    for img_path in images:\n",
    "        print(f\" - {img_path}\") \"\"\"\n",
    "# Выведем на экран\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def create_thumbnail(image_path, thumbnail_size=(100, 100)):\n",
    "    with Image.open(image_path) as img:\n",
    "        img.thumbnail(thumbnail_size)\n",
    "        return img\n",
    "\n",
    "\n",
    "def display_clustered_images(clustered_images, images_per_row=5):\n",
    "    for cluster_id, images in clustered_images.items():\n",
    "        print(f\"Cluster {cluster_id} contains {len(images)} images.\")\n",
    "        num_rows = int(np.ceil(len(images) / images_per_row))\n",
    "        num_cols = min(images_per_row, len(images))\n",
    "\n",
    "        if len(images) == 1:\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n",
    "            axs = np.array([[axs]])  # Обеспечиваем 2D массив для единообразия\n",
    "        else:\n",
    "            fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 3 * num_rows))\n",
    "            axs = np.atleast_2d(axs)  # Убеждаемся, что axs всегда 2D массив\n",
    "\n",
    "        # Преобразуем axs в 1D массив для упрощения итерации\n",
    "        axs_flat = axs.ravel()\n",
    "\n",
    "        for ax, img_path in zip(axs_flat, images):\n",
    "            thumbnail = create_thumbnail(img_path)\n",
    "            ax.imshow(thumbnail)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        # Скрываем пустые ячейки\n",
    "        for ax in axs_flat[len(images) :]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Отображаем изображения по кластерам\n",
    "display_clustered_images(clustered_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение признаков с помощью Пространственной Пирамиды\n",
    "\n",
    "Для классификации изображений с использованием пространственной пирамиды, мы адаптируем предыдущий алгоритм, добавив этап создания пространственной пирамиды изображений перед кластеризацией с помощью K-средних. Это позволит нам учитывать локальные признаки на разных масштабах, что может улучшить точность классификации.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_pyramid_features(img_path, model, levels=[1, 2, 4]):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    # Исходные размеры изображения\n",
    "    base_height, base_width = img_array.shape[1:3]\n",
    "\n",
    "    features = []\n",
    "    for level in levels:\n",
    "        for y in range(level):\n",
    "            for x in range(level):\n",
    "                # Вычисление координат области для текущего уровня\n",
    "                width = base_width // level\n",
    "                height = base_height // level\n",
    "                x_start = x * width\n",
    "                y_start = y * height\n",
    "\n",
    "                # Вырезаем часть изображения и извлекаем признаки\n",
    "                img_crop = img_array[:, y_start : y_start + height, x_start : x_start + width, :]\n",
    "                crop_features = model.predict(img_crop)\n",
    "                features.append(crop_features.flatten())\n",
    "\n",
    "    # Объединение признаков со всех уровней\n",
    "    final_features = np.concatenate(features)\n",
    "    return final_features\n",
    "\n",
    "\n",
    "# Загрузка модели\n",
    "model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "# Пример извлечения признаков\n",
    "img_path = \"./data/plibrary/justfaces/img_09.jpg\"\n",
    "features = extract_pyramid_features(img_path, model)\n",
    "\n",
    "print(f\"Извлеченные признаки: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pyramid_features(img_path, model, levels=[1, 2, 4]):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    features = []\n",
    "    for level in levels:\n",
    "        scale = 224 // level\n",
    "        for y in range(level):\n",
    "            for x in range(level):\n",
    "                # Изменение размера и обрезка для создания пирамиды\n",
    "                resized_img = image.smart_resize(img_array, (scale * level, scale * level))\n",
    "                cropped_img = resized_img[:, y * scale : (y + 1) * scale, x * scale : (x + 1) * scale, :]\n",
    "                # Извлечение признаков\n",
    "                feature = model.predict(cropped_img).flatten()\n",
    "                features.append(feature)\n",
    "\n",
    "    # Объединение признаков со всех уровней\n",
    "    final_features = np.concatenate(features)\n",
    "    return final_features\n",
    "\n",
    "\n",
    "# Загрузка предварительно обученной модели\n",
    "model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "# Извлечение признаков из всех изображений в папке\n",
    "features_list, images_paths = get_features_from_folder(folder_path)\n",
    "\n",
    "# Квантование признаков\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(features_list)\n",
    "\n",
    "# Находим индекс центроида для каждого изображения\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Группировка изображений по кластерам\n",
    "clustered_images = {}\n",
    "for i, label in enumerate(labels):\n",
    "    clustered_images.setdefault(label, []).append(images_paths[i])\n",
    "\n",
    "# Отображаем изображения по кластерам\n",
    "display_clustered_images(clustered_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Загрузка предварительно обученной модели ResNet50 без верхнего слоя\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "\n",
    "\n",
    "def extract_features(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    return features.flatten()\n",
    "\n",
    "\n",
    "def extract_pyramid_features(img_path, model, levels=[1, 2, 4]):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "\n",
    "    features = []\n",
    "    for level in levels:\n",
    "        level_features = []\n",
    "        step_size = 224 // level\n",
    "        for y in range(level):\n",
    "            for x in range(level):\n",
    "                crop = preprocessed_img[:, y * step_size : (y + 1) * step_size, x * step_size : (x + 1) * step_size, :]\n",
    "                crop_features = model.predict(crop).flatten()\n",
    "                level_features.append(crop_features)\n",
    "        features.extend(level_features)\n",
    "    return np.concatenate(features)\n",
    "\n",
    "\n",
    "def get_features_from_folder(folder_path):\n",
    "    features_list = []\n",
    "    images_paths = []\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        if img_name.lower().endswith((\"png\", \"jpg\", \"jpeg\")):\n",
    "            img_path = os.path.join(folder_path, img_name)\n",
    "            features = extract_pyramid_features(img_path, model)\n",
    "            features_list.append(features)\n",
    "            images_paths.append(img_path)\n",
    "    return features_list, images_paths\n",
    "\n",
    "\n",
    "# Извлекаем признаки из всех изображений в папке\n",
    "script_dir = os.getcwd()\n",
    "folder_path = os.path.join(script_dir, \"./data/plibrary/justfaces\")\n",
    "features_list, images_paths = get_features_from_folder(folder_path)\n",
    "\n",
    "# Применяем K-средние для квантования признаков\n",
    "num_clusters = 4  # Примерное количество ожидаемых групп\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(features_list)\n",
    "\n",
    "# Находим индекс центроида для каждого изображения\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Группировка изображений по кластерам\n",
    "clustered_images = {}\n",
    "for i, label in enumerate(labels):\n",
    "    clustered_images.setdefault(label, []).append(images_paths[i])\n",
    "\n",
    "\n",
    "def display_clustered_images(clustered_images, images_per_row=5):\n",
    "    for cluster_id, images in clustered_images.items():\n",
    "        print(f\"Cluster {cluster_id} contains {len(images)} images.\")\n",
    "        num_rows = int(np.ceil(len(images) / images_per_row))\n",
    "        num_cols = min(images_per_row, len(images))\n",
    "\n",
    "        if len(images) == 1:\n",
    "            fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n",
    "            axs = np.array([[axs]])  # Обеспечиваем 2D массив для единообразия\n",
    "        else:\n",
    "            fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 3 * num_rows))\n",
    "            axs = np.atleast_2d(axs)  # Убеждаемся, что axs всегда 2D массив\n",
    "\n",
    "        # Преобразуем axs в 1D массив для упрощения итерации\n",
    "        axs_flat = axs.ravel()\n",
    "\n",
    "        for ax, img_path in zip(axs_flat, images):\n",
    "            thumbnail = create_thumbnail(img_path)\n",
    "            ax.imshow(thumbnail)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        # Скрываем пустые ячейки\n",
    "        for ax in axs_flat[len(images) :]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Вывод результатов группировки\n",
    "display_clustered_images(clustered_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с векторной БД\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "\n",
    "# Предполагаем, что extract_pyramid_features и model уже определены\n",
    "feature_dim = 43008  # Задайте размерность вашего вектора признаков\n",
    "index = AnnoyIndex(feature_dim, \"euclidean\")  # Используем Евклидово расстояние\n",
    "\n",
    "features_list, images_paths = get_features_from_folder(folder_path)\n",
    "for i, features in enumerate(features_list):\n",
    "    index.add_item(i, features)\n",
    "\n",
    "index.build(10)  # 10 деревьев\n",
    "index.save(\"./data/image_features.ann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка индекса\n",
    "index = AnnoyIndex(feature_dim, \"euclidean\")\n",
    "index.load(\"./data/image_features.ann\")\n",
    "\n",
    "# Извлечение признаков для целевого изображения\n",
    "target_features = extract_pyramid_features(\"./data/plibrary/justfaces/img_06.jpg\", model)\n",
    "\n",
    "# Поиск ближайших соседей\n",
    "nearest_ids = index.get_nns_by_vector(target_features, 5)  # Ищем 5 ближайших соседей\n",
    "\n",
    "# Получение путей к ближайшим изображениям\n",
    "nearest_image_paths = [images_paths[i] for i in nearest_ids]\n",
    "\n",
    "print(nearest_image_paths)\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def display_images(image_paths):\n",
    "    fig, axes = plt.subplots(1, len(image_paths), figsize=(20, 10))\n",
    "    for ax, img_path in zip(axes, image_paths):\n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "display_images(nearest_image_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
